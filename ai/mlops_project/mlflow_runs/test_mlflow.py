#!/usr/bin/env python3
"""
MLflow ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” MLflowì˜ ê¸°ë³¸ ê¸°ëŠ¥ë“¤ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import os
import sys
import numpy as np
import pandas as pd
from datetime import datetime

# MLflow ìœ í‹¸ë¦¬í‹° import (ìƒëŒ€ ê²½ë¡œë¡œ ìˆ˜ì •)
from .mlflow_utils import get_mlflow_manager

def test_basic_logging():
    """ê¸°ë³¸ ë¡œê¹… ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("=== ê¸°ë³¸ ë¡œê¹… ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
    
    mlflow_manager = get_mlflow_manager("test_experiment")
    
    with mlflow_manager.start_run(run_name="basic_test") as run:
        # íŒŒë¼ë¯¸í„° ë¡œê¹…
        params = {
            "test_param1": "value1",
            "test_param2": 42,
            "test_param3": 3.14
        }
        mlflow_manager.log_parameters(params)
        
        # ë©”íŠ¸ë¦­ ë¡œê¹…
        metrics = {
            "test_metric1": 0.95,
            "test_metric2": 0.05
        }
        mlflow_manager.log_metrics(metrics)
        
        # ë”ë¯¸ ë°ì´í„°í”„ë ˆì„ ë¡œê¹…
        df = pd.DataFrame({
            "col1": [1, 2, 3],
            "col2": ["a", "b", "c"]
        })
        mlflow_manager.log_dataframe(df, "test_data", "dummy_data")
        
        print(f"âœ“ ê¸°ë³¸ ë¡œê¹… í…ŒìŠ¤íŠ¸ ì™„ë£Œ - Run ID: {run.info.run_id}")
        return run.info.run_id

def test_model_logging():
    """ëª¨ë¸ ë¡œê¹… ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n=== ëª¨ë¸ ë¡œê¹… ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
    
    mlflow_manager = get_mlflow_manager("test_experiment")
    
    with mlflow_manager.start_run(run_name="model_test") as run:
        # ë”ë¯¸ ëª¨ë¸ ì •ë³´
        model_info = {
            "model_type": "test_model",
            "version": "1.0.0",
            "description": "Test model for MLflow",
            "created_at": datetime.now().isoformat()
        }
        
        # ëª¨ë¸ ì •ë³´ ì €ì¥
        mlflow_manager.save_model_info("/tmp", model_info, "test_model_info")
        
        # ë”ë¯¸ ì•„í‹°íŒ©íŠ¸ ë¡œê¹…
        dummy_file = "/tmp/test_artifact.txt"
        with open(dummy_file, 'w') as f:
            f.write("This is a test artifact")
        
        mlflow_manager.log_artifacts(dummy_file, "test_artifacts")
        
        # íŒŒì¼ ì •ë¦¬
        os.remove(dummy_file)
        
        print(f"âœ“ ëª¨ë¸ ë¡œê¹… í…ŒìŠ¤íŠ¸ ì™„ë£Œ - Run ID: {run.info.run_id}")
        return run.info.run_id

def test_experiment_manager():
    """ì‹¤í—˜ ê´€ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n=== ì‹¤í—˜ ê´€ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
    
    from .mlflow_experiment_manager import MLflowExperimentManager
    
    manager = MLflowExperimentManager("test_experiment")
    
    # ì‹¤í—˜ ëª©ë¡ ì¡°íšŒ
    experiments = manager.list_experiments()
    print(f"âœ“ ì‹¤í—˜ ëª©ë¡ ì¡°íšŒ: {len(experiments)}ê°œ ì‹¤í—˜")
    
    # ì‹¤í–‰ ëª©ë¡ ì¡°íšŒ
    runs = manager.list_runs("test_experiment")
    print(f"âœ“ ì‹¤í–‰ ëª©ë¡ ì¡°íšŒ: {len(runs)}ê°œ ì‹¤í–‰")
    
    if runs:
        # ì²« ë²ˆì§¸ ì‹¤í–‰ ì •ë³´ ì¶œë ¥
        first_run = runs[0]
        print(f"âœ“ ì²« ë²ˆì§¸ ì‹¤í–‰: {first_run['run_id']}")
        print(f"  - ìƒíƒœ: {first_run['status']}")
        print(f"  - íŒŒë¼ë¯¸í„°: {len(first_run['parameters'])}ê°œ")
        print(f"  - ë©”íŠ¸ë¦­: {len(first_run['metrics'])}ê°œ")
    
    return True

def test_mlflow_connection():
    """MLflow ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("\n=== MLflow ì—°ê²° í…ŒìŠ¤íŠ¸ ===")
    
    try:
        import mlflow
        
        # MLflow ì„œë²„ ìƒíƒœ í™•ì¸
        tracking_uri = mlflow.get_tracking_uri()
        print(f"âœ“ MLflow Tracking URI: {tracking_uri}")
        
        # ì‹¤í—˜ ëª©ë¡ í™•ì¸
        experiments = mlflow.search_experiments()
        print(f"âœ“ ì—°ê²°ëœ ì‹¤í—˜ ìˆ˜: {len(experiments)}")
        
        return True
        
    except Exception as e:
        print(f"âœ— MLflow ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("MLflow ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    test_results = []
    
    # 1. MLflow ì—°ê²° í…ŒìŠ¤íŠ¸
    test_results.append(("ì—°ê²° í…ŒìŠ¤íŠ¸", test_mlflow_connection()))
    
    # 2. ê¸°ë³¸ ë¡œê¹… í…ŒìŠ¤íŠ¸
    try:
        run_id = test_basic_logging()
        test_results.append(("ê¸°ë³¸ ë¡œê¹…", True))
    except Exception as e:
        print(f"âœ— ê¸°ë³¸ ë¡œê¹… í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        test_results.append(("ê¸°ë³¸ ë¡œê¹…", False))
    
    # 3. ëª¨ë¸ ë¡œê¹… í…ŒìŠ¤íŠ¸
    try:
        run_id = test_model_logging()
        test_results.append(("ëª¨ë¸ ë¡œê¹…", True))
    except Exception as e:
        print(f"âœ— ëª¨ë¸ ë¡œê¹… í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        test_results.append(("ëª¨ë¸ ë¡œê¹…", False))
    
    # 4. ì‹¤í—˜ ê´€ë¦¬ í…ŒìŠ¤íŠ¸
    try:
        test_experiment_manager()
        test_results.append(("ì‹¤í—˜ ê´€ë¦¬", True))
    except Exception as e:
        print(f"âœ— ì‹¤í—˜ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        test_results.append(("ì‹¤í—˜ ê´€ë¦¬", False))
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 50)
    print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
    print("=" * 50)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ“ PASS" if result else "âœ— FAIL"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nì´ {total}ê°œ í…ŒìŠ¤íŠ¸ ì¤‘ {passed}ê°œ í†µê³¼")
    
    if passed == total:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
    else:
        print("âš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
