x-airflow-common: &airflow-common
  image: apache/airflow:2.7.1-python3.10
  build:
    context: ./airflow
    dockerfile: Dockerfile
  environment:
    TZ: Asia/Seoul
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@sobi-db:5432/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://web-redis:6379/0
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@sobi-db:5432/airflow
    AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "false"
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    PYTHONPATH: /opt/airflow:/opt/airflow/ai   
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./ai:/opt/airflow/ai:ro                   
  networks:
    - sobi-net

services:
  airflow-webserver:
    <<: *airflow-common
    command: webserver
    depends_on:
      - airflow-init
    ports:
      - "8089:8080"

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    depends_on:
      - airflow-init

  airflow-init:
    <<: *airflow-common
    restart: "no"
    command: >
      bash -c "
        airflow db init &&
        airflow users create --username admin --password admin --firstname admin --lastname admin --role Admin --email admin@example.com
      "

  mlflow:
    image: bitnami/mlflow:3.1.4-debian-12-r6
    ports:
      - "5000:5000"
    command: >
      mlflow server
      --backend-store-uri postgresql+psycopg2://airflow:airflow@sobi-db:5432/mlflow
      --default-artifact-root /bitnami/mlflow/artifacts
      --host 0.0.0.0
      --port 5000
    volumes:
      - ./mlflow/mlruns:/bitnami/mlflow/artifacts
    networks:
      - sobi-net

networks:
  sobi-net:
    external: true
